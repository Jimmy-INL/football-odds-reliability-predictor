{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Football Odds - Reliability Predictor\n",
    "Find out the most trustworthy football game out of all the scheduled English Premier League matches for tomorrow. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![deduced.PNG](img/deduced.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phases:\n",
    "\n",
    "1. Fetch all the historical betting odds data from season 2000/2001 onwards - every time the code executes it fetches the most updated data for the current season - and compute the average odds value (among all the available betting companies) for each particular match played for the three potential results Home/Draw/Away separately.\n",
    "\n",
    "2. Scrape the William Hill bookmaker page and bring the list of all the scheduled English Premier League tomorrow's matches along with their offered odds for each potential outcome Home/Draw/Away.\n",
    "\n",
    "3. For each one of the upcoming matches, filter out the initial database accordingly in order to keep only the given pair of teams over the years (and the respective odds). So, given the exact date of each game, and representing each of the three outcomes Home/Draw/Away as value y, can predict the next value of each of the three possible results as a time series next step. This is done utilizing the famous Facebook's Prophet forecasting algorithm which is robust to missing data, shifts in the trend, and large outliers.\n",
    "\n",
    "4. Compute the sum of the distances between the three results among the offered and the predicted values for each one of the listed matches and pick the one with the minimum sum of distances. This is considered as the most reliable game to potentially bet on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import requests\n",
    "import io\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from fractions import Fraction\n",
    "\n",
    "from fbprophet import Prophet\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse data as time\n",
    "def parse_date(date):\n",
    "    if date == '':\n",
    "        return None\n",
    "    else:\n",
    "        return dt.strptime(date, '%d/%m/%y').date()\n",
    "\n",
    "# Parse data as time - different year format   \n",
    "def parse_date_other(date):\n",
    "    if date == '':\n",
    "        return None\n",
    "    else:\n",
    "        return dt.strptime(date, '%d/%m/%Y').date()\n",
    "\n",
    "def url_to_soup(url):\n",
    "    request = urllib.request.Request(url)\n",
    "    response = urllib.request.urlopen(request)\n",
    "    soup = BeautifulSoup(response, \"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def apply_prophet(slice_type):\n",
    "    model = Prophet()\n",
    "    model.fit(slice_type)\n",
    "    \n",
    "    future_data = model.make_future_dataframe(periods=1)\n",
    "    forecast_data = model.predict(future_data)\n",
    "    \n",
    "    forecast = '%.2f' % round(forecast_data.tail(1).yhat.values[0], 2)\n",
    "    \n",
    "    if float(Decimal(forecast))<1:\n",
    "        return 1\n",
    "    else:\n",
    "        return float(Decimal(forecast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "• Load data till season 2016/2017 - saved locally.<br />\n",
    "• Fetch the most updated data from season 2017/2018.<br />\n",
    "• Parse date in datetime format.<br />\n",
    "• Compute average odds per game for Home/Draw/Away separately.<br />\n",
    "• Filter out the useful columns.<br />\n",
    "• Compose the deduced merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc = \"C:/Users/alexd/OneDrive/Documents/englandm/\"\n",
    "\n",
    "raw_data_1 = pd.read_csv(loc + '2000_2001.csv')\n",
    "raw_data_2 = pd.read_csv(loc + '2001_2002.csv')\n",
    "raw_data_3 = pd.read_csv(loc + '2002_2003.csv')\n",
    "raw_data_4 = pd.read_csv(loc + '2003_2004.csv')\n",
    "raw_data_5 = pd.read_csv(loc + '2004_2005.csv', encoding='cp1252')\n",
    "raw_data_6 = pd.read_csv(loc + '2005_2006.csv')\n",
    "raw_data_7 = pd.read_csv(loc + '2006_2007.csv')\n",
    "raw_data_8 = pd.read_csv(loc + '2007_2008.csv')\n",
    "raw_data_9 = pd.read_csv(loc + '2008_2009.csv')\n",
    "raw_data_10 = pd.read_csv(loc + '2009_2010.csv')\n",
    "raw_data_11 = pd.read_csv(loc + '2010_2011.csv')\n",
    "raw_data_12 = pd.read_csv(loc + '2011_2012.csv')\n",
    "raw_data_13 = pd.read_csv(loc + '2012_2013.csv')\n",
    "raw_data_14 = pd.read_csv(loc + '2013_2014.csv')\n",
    "raw_data_15 = pd.read_csv(loc + '2014_2015.csv')\n",
    "raw_data_16 = pd.read_csv(loc + '2015_2016.csv')\n",
    "raw_data_17 = pd.read_csv(loc + '2016_2017.csv')\n",
    "\n",
    "# Get the most updated data from the current season\n",
    "data = requests.get('http://football-data.co.uk/mmz4281/1718/E0.csv').content\n",
    "raw_data_18 = pd.read_csv(io.StringIO(data.decode('utf-8')))\n",
    "\n",
    "\n",
    "for i in range(1, 19):\n",
    "    df_name = ''.join(['raw_data_', str(i)])\n",
    "    df_name = eval(df_name)\n",
    "    \n",
    "    # Properly parse the columns containing dates\n",
    "    try:\n",
    "        df_name.Date = df_name.Date.apply(parse_date)\n",
    "    except:\n",
    "        try:\n",
    "            df_name.Date = df_name.Date.apply(parse_date_other)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    # Compute the average of the columns with column name ending with H, D, A for each dataframe respectively\n",
    "    df_name['avgH'] = df_name.iloc[:, pd.Series(map(lambda x : str(x)[-1]=='H', df_name.columns)).values].mean(axis=1)\n",
    "    df_name['avgD'] = df_name.iloc[:, pd.Series(map(lambda x : str(x)[-1]=='D', df_name.columns)).values].mean(axis=1)\n",
    "    df_name['avgA'] = df_name.iloc[:, pd.Series(map(lambda x : str(x)[-1]=='A', df_name.columns)).values].mean(axis=1)\n",
    "\n",
    "# Keep only the useful columns\n",
    "columns_req = ['Date','HomeTeam','AwayTeam','avgH','avgD','avgA']\n",
    "\n",
    "data_1 = raw_data_1[columns_req]                      \n",
    "data_2 = raw_data_2[columns_req]\n",
    "data_3 = raw_data_3[columns_req]\n",
    "data_4 = raw_data_4[columns_req]\n",
    "data_5 = raw_data_5[columns_req]\n",
    "data_6 = raw_data_6[columns_req]\n",
    "data_7 = raw_data_7[columns_req]\n",
    "data_8 = raw_data_8[columns_req]\n",
    "data_9 = raw_data_9[columns_req]\n",
    "data_10 = raw_data_10[columns_req]\n",
    "data_11 = raw_data_11[columns_req]   \n",
    "data_12 = raw_data_12[columns_req]\n",
    "data_13 = raw_data_13[columns_req]\n",
    "data_14 = raw_data_14[columns_req]\n",
    "data_15 = raw_data_15[columns_req]\n",
    "data_16 = raw_data_16[columns_req]\n",
    "data_17 = raw_data_17[columns_req]\n",
    "data_18 = raw_data_18[columns_req]\n",
    "\n",
    "# FINAL DATAFRAME\n",
    "playing_stat = pd.concat([data_1,\n",
    "                          data_2,\n",
    "                          data_3,\n",
    "                          data_4,\n",
    "                          data_5,\n",
    "                          data_6,\n",
    "                          data_7,\n",
    "                          data_8,\n",
    "                          data_9,\n",
    "                          data_10,\n",
    "                          data_11,\n",
    "                          data_12,\n",
    "                          data_13,\n",
    "                          data_14,\n",
    "                          data_15,\n",
    "                          data_16,\n",
    "                          data_17,\n",
    "                          data_18], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>avgH</th>\n",
       "      <th>avgD</th>\n",
       "      <th>avgA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6685</th>\n",
       "      <td>2018-01-13</td>\n",
       "      <td>Watford</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>3.723077</td>\n",
       "      <td>3.355</td>\n",
       "      <td>2.765833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6686</th>\n",
       "      <td>2018-01-13</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>3.453077</td>\n",
       "      <td>3.072</td>\n",
       "      <td>3.844167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6687</th>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>5.259231</td>\n",
       "      <td>4.033</td>\n",
       "      <td>1.807500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6688</th>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Man City</td>\n",
       "      <td>4.105385</td>\n",
       "      <td>3.631</td>\n",
       "      <td>2.244167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6689</th>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>Man United</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>2.691538</td>\n",
       "      <td>6.775</td>\n",
       "      <td>12.262500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date     HomeTeam     AwayTeam      avgH   avgD       avgA\n",
       "6685  2018-01-13      Watford  Southampton  3.723077  3.355   2.765833\n",
       "6686  2018-01-13    West Brom     Brighton  3.453077  3.072   3.844167\n",
       "6687  2018-01-14  Bournemouth      Arsenal  5.259231  4.033   1.807500\n",
       "6688  2018-01-14    Liverpool     Man City  4.105385  3.631   2.244167\n",
       "6689  2018-01-15   Man United        Stoke  2.691538  6.775  12.262500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playing_stat.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse William Hill website & fetch tomorrow's matches (if any)\n",
    "# Compute the respective distances among Home/Draw/Away for every pair\n",
    "# Print result\n",
    "\n",
    "Special attention paid to \"no scheduled match for tomorrow\" and \"not enough data for the specific matchday pairs\" cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 3.0.\n",
      "INFO:fbprophet.forecaster:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 3.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.forecaster:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 3.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Most trustworthy game for tomorrow 22 Jan: Swansea - Liverpool at 20:00 UK\n",
      "\n",
      "Predicted odds for Home/Draw/Away: 5.63/10.91/1\n",
      "\n",
      "William Hill odds for Home/Draw/Away: 11.0/5.5/1.3\n"
     ]
    }
   ],
   "source": [
    "# Get tomorrow's odds\n",
    "url = 'http://sports.williamhill.com/bet/en-gb/betting/y/5/tm/1/Football.html'\n",
    "\n",
    "this_soup = url_to_soup(url)\n",
    "\n",
    "english_premier_league = this_soup.find(\"div\", {\"id\": \"ip_type_295\"})\n",
    "\n",
    "if english_premier_league is not None:\n",
    "\n",
    "    lst=[]\n",
    "    \n",
    "    for tr in english_premier_league.find_all(\"tr\", {\"class\":\"rowOdd\"}):\n",
    "        this_dict = {}\n",
    "        i=0\n",
    "        for td in tr.find_all(\"td\"):\n",
    "            if not td.text == '\\n\\n' and not td.text == '\\n' and \"Bets\" not in td.text:\n",
    "                if i==0:\n",
    "                    this_dict[\"date\"] = td.text.strip()\n",
    "                    i+=1\n",
    "                elif i==1:\n",
    "                    this_dict[\"time\"] = td.text.strip()\n",
    "                    i+=1\n",
    "                elif i==2:\n",
    "                    this_dict[\"homeTeam\"] = td.text.split(\"\\n\")[1].split(\"\\xa0\")[0].strip()\n",
    "                    this_dict[\"awayTeam\"] = td.text.split(\"\\n\")[1].split(\"\\xa0\")[-1].strip()\n",
    "                    i+=1\n",
    "                elif i==3:\n",
    "                    oddH = td.text.split(\"\\n\\n\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\")[1].split(\"\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\n\\n\")[0].strip()\n",
    "                    # EVS: For every 1 unit you stake, you will receive 1 unit if you win (plus your stake)\n",
    "                    if not oddH == 'EVS':\n",
    "                        this_dict[\"oddH\"] = round(float(Fraction(oddH))+1, 2)\n",
    "                    else:\n",
    "                        this_dict[\"oddH\"] = 2\n",
    "                    i+=1\n",
    "                elif i==4:\n",
    "                    oddD = td.text.split(\"\\n\\n\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\")[1].split(\"\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\n\\n\")[0].strip()\n",
    "                    if not oddD == 'EVS':\n",
    "                        this_dict[\"oddD\"] = round(float(Fraction(oddD))+1, 2)\n",
    "                    else:\n",
    "                        this_dict[\"oddD\"] = 2\n",
    "                    i+=1\n",
    "                elif i==5:\n",
    "                    oddA = td.text.split(\"\\n\\n\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\")[1].split(\"\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\n\\n\")[0].strip()\n",
    "                    if not oddA == 'EVS':\n",
    "                        this_dict[\"oddA\"] = round(float(Fraction(oddA))+1, 2)\n",
    "                    else:\n",
    "                        this_dict[\"oddA\"] = 2\n",
    "                    i+=1\n",
    "                lst.append(this_dict)\n",
    "                \n",
    "    up_matches = pd.DataFrame.from_dict(lst)\n",
    "    up_matches.drop_duplicates(inplace=True)\n",
    "    up_matches = up_matches.reset_index(drop=True)\n",
    "    up_matches = up_matches.replace(\"Man Utd\", \"Man United\")\n",
    "\n",
    "    pred=[]\n",
    "    \n",
    "    for team_no in range(0, up_matches.shape[0]):\n",
    "        pred_dict = {}\n",
    "        hTeam = up_matches.homeTeam[team_no]\n",
    "        aTeam = up_matches.awayTeam[team_no]\n",
    "        pred_dict['homeTeam'] = hTeam\n",
    "        pred_dict['awayTeam'] = aTeam\n",
    "    \n",
    "        playing_stat_temp = playing_stat[(playing_stat.HomeTeam == hTeam) & \n",
    "                                         (playing_stat.AwayTeam == aTeam)]\n",
    "        \n",
    "        if len(playing_stat_temp) != 0:\n",
    "            for odd_type in ['avgH', 'avgD', 'avgA']:\n",
    "                # Convert gradually all the odd categories into time series.\n",
    "                playing_stat_slice = playing_stat_temp[['Date',odd_type]].reset_index(drop=True)\n",
    "                playing_stat_slice.rename(columns={'Date': 'ds', odd_type: 'y'}, inplace=True)\n",
    "                \n",
    "                pred_dict[odd_type] = apply_prophet(playing_stat_slice)\n",
    "                print()\n",
    "                \n",
    "            pred.append(pred_dict)\n",
    "        else:\n",
    "            # Not enough data for the specific pair.\n",
    "            continue\n",
    "    \n",
    "    pred_odds = pd.DataFrame.from_dict(pred)\n",
    "    \n",
    "    if len(pred_odds) != 0:\n",
    "        \n",
    "        dist=[]\n",
    "        \n",
    "        for team_no in range(0, up_matches.shape[0]):\n",
    "            dist_dict={}\n",
    "            dist_dict['homeTeam'] = up_matches.homeTeam.values[0]\n",
    "            dist_dict['awayTeam'] = up_matches.awayTeam.values[0]\n",
    "            dist_dict['time'] = up_matches.time.values[0]\n",
    "            dist_dict['date'] = up_matches.date.values[0]\n",
    "            dist_dict['predH'] = pred_odds.avgH.values[0]\n",
    "            dist_dict['predD'] = pred_odds.avgD.values[0]\n",
    "            dist_dict['predA'] = pred_odds.avgA.values[0]\n",
    "            dist_dict['whH'] = up_matches.oddH.values[0]\n",
    "            dist_dict['whD'] = up_matches.oddD.values[0]\n",
    "            dist_dict['whA'] = up_matches.oddA.values[0]\n",
    "            \n",
    "            dist_dict['dist'] = float(abs(up_matches.oddH - pred_odds.avgH) +\n",
    "                                abs(up_matches.oddD - pred_odds.avgD) + \n",
    "                                abs(up_matches.oddA - pred_odds.avgA))\n",
    "            \n",
    "            dist.append(dist_dict)\n",
    "            \n",
    "        dist_from_pred = pd.DataFrame.from_dict(dist)\n",
    "        \n",
    "        min_dist_match = dist_from_pred.loc[dist_from_pred.dist.idxmin()]\n",
    "        \n",
    "        print(\"Most trustworthy game for tomorrow \" + min_dist_match.date + \": \" + \n",
    "              min_dist_match.homeTeam + \" - \" + min_dist_match.awayTeam + \n",
    "              \" at \" + min_dist_match.time)\n",
    "        print()\n",
    "        print(\"Predicted odds for Home/Draw/Away: \" + str(min_dist_match.predH) +\n",
    "              \"/\" + str(min_dist_match.predD) + \"/\" + str(min_dist_match.predA))\n",
    "        print()\n",
    "        print(\"William Hill odds for Home/Draw/Away: \" + \n",
    "              str(min_dist_match.whH) + \"/\" + str(min_dist_match.whD) + \"/\" +\n",
    "              str(min_dist_match.whA))\n",
    "    else:\n",
    "        print(\"Not enough data for this matchday pairs.\")\n",
    "\n",
    "else:\n",
    "    print()\n",
    "    print(\"No scheduled English Premier League matches for tomorrow.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
